import json, requests, time, os, re, base58
from concurrent.futures import ThreadPoolExecutor

# æŠ“å–æ± ï¼š2026å¹´æ´»è·ƒçš„é«˜ååé‡æ•°æ®æº
POOL_URLS = [
    "https://raw.githubusercontent.com/gaotianliuyun/gao/master/0827.json",
    "https://itvbox.top/tv",
    "http://cdn.qiaoji8.com/tvbox.json",
    "http://bbk.888tv.tv/itvbox.json",
    "http://meitv.top/itvbox.json",
    "http://120.79.4.185/new.json",
    "https://ghproxy.com/https://raw.githubusercontent.com/ssili126/tv/main/itvbox.json",
    "https://raw.githubusercontent.com/FongMi/Release/main/levon.json",
    "http://home.jundie.top:81/top98.json",
    "https://t-v.me/tv.json",
    "http://pandown.pro/tvbox/m.json"
]

def check_source(name, api):
    """æ£€æµ‹æ¥å£æ˜¯å¦æœ‰æ•ˆï¼Œå®½å®¹åº¦è®¾ä¸º 15 ç§’ä»¥ä¿ç•™é«˜ååé‡è“å…‰æº"""
    try:
        res = requests.get(api, timeout=15, headers={'User-Agent': 'Mozilla/5.0'}, verify=False)
        if res.status_code == 200:
            return {"api": api, "name": name, "delay": res.elapsed.total_seconds()}
    except:
        pass
    return None

def generate():
    raw_links = set()
    print("Step 1: æ­£åœ¨ä»å…¨ç½‘æœåˆ®æ¥å£...")
    
    for url in POOL_URLS:
        try:
            r = requests.get(url, timeout=10, verify=False)
            # å…¼å®¹æ­£åˆ™åŒ¹é… API æ¥å£
            found = re.findall(r'"(https?://[^"]+/api\.php/provide/vod[^"]*)"', r.text)
            for link in found:
                raw_links.add(link)
        except:
            continue
    
    print(f"æ‰¾åˆ°æ½œåœ¨æ¥å£ {len(raw_links)} ä¸ªï¼Œå¼€å§‹å¹¶è¡Œæ£€æµ‹...")

    valid_results = []
    with ThreadPoolExecutor(max_workers=50) as exe:
        futures = [exe.submit(check_source, f"æº_{i}", url) for i, url in enumerate(list(raw_links))]
        for f in futures:
            res = f.result()
            if res:
                valid_results.append(res)
    
    # æŒ‰ç…§å“åº”é€Ÿåº¦æ’åºï¼Œå–å‰ 80 ä¸ª
    valid_results.sort(key=lambda x: x['delay'])
    final_list = valid_results[:80]

    api_site = {}
    for i, item in enumerate(final_list):
        key = f"api_{i+1}"
        api_site[key] = {
            "api": item['api'],
            "name": f"ğŸš€ æº_{i+1:02d} | {int(item['delay']*1000)}ms",
            "detail": item['api'].split('api.php')[0]
        }

    # æ„é€ æ ‡å‡† DecoTV åµŒå¥—æ ¼å¼
    config = {
        "cache_time": 9200,
        "api_site": api_site,
        "custom_category": [
            { "name": "åè¯­ç²¾é€‰", "type": "movie", "query": "åè¯­" },
            { "name": "4Kææ¸…", "type": "movie", "query": "4K" }
        ]
    }

    # --- ä¿å­˜ JSON æ–‡ä»¶ ---
    with open("tv.json", "w", encoding="utf-8") as f:
        json.dump(config, f, ensure_ascii=False, indent=2)
    print(f"âœ… tv.json å·²æ›´æ–°")

    # --- ç”Ÿæˆ Base58 ç¼–ç æ–‡ä»¶ ---
    # ç›´æ¥ä½¿ç”¨å½“å‰å†…å­˜ä¸­çš„ config å¯¹è±¡ï¼Œç¡®ä¿æ•°æ®ä¸€è‡´
    compact_json = json.dumps(config, ensure_ascii=False).encode('utf-8')
    b58_text = base58.b58encode(compact_json).decode('utf-8')

    with open("deco_b58.txt", "w", encoding="utf-8") as f:
        f.write(b58_text)
    print("âœ… deco_b58.txt å·²æ›´æ–°")

if __name__ == "__main__":
    # ç¦ç”¨ HTTPS è­¦å‘Š
    try:
        requests.packages.urllib3.disable_warnings()
    except:
        pass
    generate()
