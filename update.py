import json, requests, time, os, re
from concurrent.futures import ThreadPoolExecutor

# å…¨ç½‘æ¥å£æ± 
POOL_URLS = [
    "https://raw.githubusercontent.com/gaotianliuyun/gao/master/0827.json",
    "https://itvbox.top/tv",
    "http://cdn.qiaoji8.com/tvbox.json"
]

def check_speed(name, key, api):
    start_time = time.time()
    try:
        # å…è®¸ 10s é«˜å»¶è¿Ÿï¼Œä¿ç•™é‡å‹å¸¦å®½æº
        res = requests.get(api, timeout=10, headers={'User-Agent': 'Mozilla/5.0'})
        if res.status_code == 200:
            return (key, name, api, time.time() - start_time)
    except: pass
    return (key, name, api, 999) # å¤±è´¥ä¿åº•

def generate():
    all_raw = {}
    for url in POOL_URLS:
        try:
            r = requests.get(url, timeout=5)
            links = re.findall(r'"(https?://[^"]+/api\.php/provide/vod[^"]*)"', r.text)
            for i, link in enumerate(links):
                all_raw[f"auto_{hash(link)%10000}"] = [f"ğŸš€ è‡ªåŠ¨æº_{i}", link]
        except: continue
    
    # å¼ºåˆ¶åŒ…å«é«˜å¸¦å®½å›ºå®šæº
    all_raw["sn_4k"] = ["ğŸ’ ç´¢å°¼Â·4Ké‡å‹", "https://suoniapi.com/api.php/provide/vod"]

    results = []
    with ThreadPoolExecutor(max_workers=30) as exe:
        futures = [exe.submit(check_speed, v[0], k, v[1]) for k, v in all_raw.items()]
        results = [f.result() for f in futures]
    
    # æ’åºå¹¶å–å‰ 50 ä¸ª
    results.sort(key=lambda x: x[3])
    top_50 = results[:50]
    
    api_site = {r[0]: {"api": r[2], "name": f"{r[1]} | {int(r[3]*1000) if r[3]<999 else 'æé€Ÿçº¿'}ms", "detail": r[2]} for r in top_50}
    config = {"cache_time": 9200, "api_site": api_site, "custom_category": [{"name": "å…¨ç½‘æ€¥é€ŸÂ·æœåˆ®", "type": "movie", "query": "4K"}]}
    
    # ç›´æ¥ä¿å­˜åœ¨æ ¹ç›®å½•ï¼Œæ–¹ä¾¿ CDN æ‹‰å–
    with open("tv.json", "w", encoding="utf-8") as f:
        json.dump(config, f, ensure_ascii=False, indent=2)

if __name__ == "__main__": generate()
