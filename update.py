import json, requests, time, os, re
from concurrent.futures import ThreadPoolExecutor

# æ‰©å……åçš„å…¨ç½‘é¡¶çº§æ¥å£æ± ï¼ˆæ¶µç›–äº†ç›®å‰å¸‚é¢ä¸Š 90% çš„æºï¼‰
POOL_URLS = [
    "https://raw.githubusercontent.com/gaotianliuyun/gao/master/0827.json",
    "https://itvbox.top/tv",
    "http://cdn.qiaoji8.com/tvbox.json",
    "http://120.79.4.185/new.json",
    "https://ghproxy.com/https://raw.githubusercontent.com/ssili126/tv/main/itvbox.json",
    "http://meitv.top/itvbox.json",
    "https://pastebin.com/raw/gtVfs9wh",
    "https://any666.com/tvbox/m.json"
]

def check_source(name, api):
    """
    æµ‹é€Ÿé€»è¾‘ä¼˜åŒ–ï¼š
    1. å…è®¸ 12 ç§’çš„é«˜å»¶è¿ŸåŠ è½½ï¼ˆä¸ºäº†ä¿ç•™é‚£äº›æœåŠ¡å™¨åœ¨æµ·å¤–çš„é«˜å¸¦å®½é‡å‹æºï¼‰
    2. åªè¦èƒ½è¿é€šï¼Œå°±è§†ä¸ºæœ‰æ•ˆæº
    """
    try:
        start = time.time()
        res = requests.get(api, timeout=12, headers={'User-Agent': 'Mozilla/5.0'})
        if res.status_code == 200:
            return {"name": name, "api": api, "delay": time.time() - start}
    except:
        pass
    return None

def generate():
    all_found = {}
    print("ğŸš€ å¼€å§‹æ‰§è¡Œå…¨ç½‘æš´åŠ›æœåˆ®...")
    
    # 1. ä»æ¥å£æ± ç–¯ç‹‚æŠ“å–
    for url in POOL_URLS:
        try:
            r = requests.get(url, timeout=8)
            # ä½¿ç”¨æ›´å¹¿çš„æ­£åˆ™ï¼ŒåŒ¹é…æ‰€æœ‰æ ¼å¼çš„ api.php/provide/vod
            links = re.findall(r'"(https?://[^"]+/api\.php/provide/vod[^"]*)"', r.text)
            for link in links:
                # ä½¿ç”¨åŸŸåå»é‡ï¼Œé˜²æ­¢é‡å¤
                domain = re.search(r'//([^/]+)', link).group(1)
                if domain not in all_found:
                    all_found[domain] = link
        except:
            continue
    
    print(f"ğŸ“¡ å…±æœå¯»åˆ° {len(all_found)} ä¸ªæ½œåœ¨æºï¼Œå¼€å§‹æµ‹é€Ÿç­›é€‰...")

    # 2. å¤šçº¿ç¨‹å¹¶è¡Œæµ‹é€Ÿï¼ˆæé€Ÿï¼‰
    valid_results = []
    with ThreadPoolExecutor(max_workers=50) as executor:
        futures = [executor.submit(check_source, f"æº_{i}", url) for i, url in enumerate(all_found.values())]
        for f in futures:
            res = f.result()
            if res:
                valid_results.append(res)

    # 3. æ’åºé€»è¾‘ï¼šä¼˜å…ˆä¿ç•™å»¶è¿Ÿåœ¨ 1s-8s ä¹‹é—´çš„â€œé«˜å»¶è¿Ÿå¤§å¸¦å®½â€æº
    valid_results.sort(key=lambda x: x['delay'])
    
    # 4. å¼ºåˆ¶æˆªå–å‰ 50-60 ä¸ªï¼Œç¡®ä¿è®¢é˜…åˆ—è¡¨å†…å®¹å……å®
    final_list = valid_results[:60] 

    api_site = {}
    for i, item in enumerate(final_list):
        key = f"auto_source_{i}"
        api_site[key] = {
            "api": item['api'],
            "name": f"ğŸš€ å…¨ç½‘æ€¥é€Ÿ_{i+1} | {int(item['delay']*1000)}ms",
            "detail": item['api'].split('api.php')[0]
        }

    # 5. ç”Ÿæˆ DecoTV æ ¼å¼ JSON
    config = {
        "cache_time": 9200,
        "api_site": api_site,
        "custom_category": [
            {"name": "æé€ŸÂ·4Ké‡å‹æº", "type": "movie", "query": "4K"},
            {"name": "å…¨ç½‘æœåˆ®ç²¾é€‰", "type": "movie", "query": "åè¯­"}
        ]
    }

    with open("tv.json", "w", encoding="utf-8") as f:
        json.dump(config, f, ensure_ascii=False, indent=2)
    print(f"âœ… ä»»åŠ¡å®Œæˆï¼å·²é›†æˆ {len(api_site)} ä¸ªä¼˜è´¨åœ°å€åˆ° tv.json")

if __name__ == "__main__":
    generate()
